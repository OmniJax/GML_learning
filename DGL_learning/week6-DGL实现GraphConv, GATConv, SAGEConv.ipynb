{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YqM5Z7qKUgqS"
   },
   "source": [
    "In this week, you are required to implement a toy GATConv and SAGEConv based on document. Also, you need to implement both in PyG and DGL. In this work, you will get a further understanding of tensor-centric in PyG and graph-centric in DGL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DGL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GraphConv\n",
    "Mathematically it is defined as follows:\n",
    "\n",
    "$$\n",
    "  h_i^{(l+1)} = \\sigma(b^{(l)} + \\sum_{j\\in\\mathcal{N}(i)}\\frac{1}{c_{ji}}h_j^{(l)}W^{(l)})\n",
    "$$\n",
    "where $\\mathcal{N}(i)$ is the set of neighbors of node $i$, \n",
    "$c_{ji}$ is the product of the square root of node degrees\n",
    "$(i.e.,  c_{ji} = \\sqrt{|\\mathcal{N}(j)|}\\sqrt{|\\mathcal{N}(i)|})$,\n",
    "and $\\sigma$ is an activation function.\n",
    "\n",
    "If a weight tensor on each edge is provided, the weighted graph convolution is defined as:\n",
    "\n",
    "$$\n",
    "  h_i^{(l+1)} = \\sigma(b^{(l)} + \\sum_{j\\in\\mathcal{N}(i)}\\frac{e_{ji}}{c_{ji}}h_j^{(l)}W^{(l)})\n",
    "$$\n",
    "where $e_{ji}$is the scalar weight on the edge from node $j$ to node $i$.\n",
    "This is NOT equivalent to the weighted graph convolutional network formulation in the paper.\n",
    "\n",
    "To customize the normalization term :$c_{ji}$, one can first set ``norm='none'`` for\n",
    "the model, and send the pre-normalized :$e_{ji}$ to the forward computation. We provide\n",
    ":class:`~dgl.nn.pytorch.EdgeWeightNorm` to normalize scalar edge weight following the GCN paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DGL_GraphConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DGL_GraphConv, self).__init__()\n",
    "        self.W = nn.Parameter(torch.rand(in_channels, out_channels))\n",
    "        self.b = nn.Parameter(torch.rand(out_channels))\n",
    "        self.activate = nn.ReLU()\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            # 这里的normalization用了left+right，也就是考虑了出度+入度\n",
    "            norm_src = g.out_degrees().clamp(min=1).view(-1, 1)\n",
    "            norm_src = torch.pow(norm_src, -0.5)\n",
    "\n",
    "            feat_src = norm_src * h\n",
    "            feat_src = torch.matmul(feat_src, self.W)\n",
    "            g.srcdata[\"h\"] = feat_src\n",
    "            g.update_all(fn.u_mul_e(\"h\", \"edge_weight\", \"he\"), fn.sum(\"he\", \"rst\"))\n",
    "            rst = g.dstdata[\"rst\"]\n",
    "\n",
    "            norm_dst = g.in_degrees().clamp(min=1).view(-1, 1)\n",
    "            norm_dst = torch.pow(norm_dst, -0.5)\n",
    "            rst = rst * norm_dst\n",
    "\n",
    "            rst += self.b\n",
    "            return F.relu(rst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "src = torch.tensor([0, 1, 1, 2, 2, 4])\n",
    "dst = torch.tensor([2, 0, 2, 3, 4, 3])\n",
    "h = torch.ones((5, 8))\n",
    "\n",
    "g = dgl.graph((src, dst))\n",
    "g.ndata[\"h\"] = h\n",
    "edge_weight = torch.ones(g.num_edges())  # 给各个边赋格权重\n",
    "g.edata[\"edge_weight\"] = edge_weight\n",
    "plt.figure(figsize=(2, 2))\n",
    "nx.draw(dgl.to_networkx(g), with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = h.shape[1]\n",
    "out_channels = in_channels  # *2\n",
    "dgl_graphConv = DGL_GraphConv(in_channels, out_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.1296, 4.5994, 3.6825, 3.6156, 2.8758, 3.3465, 2.9255, 4.2599],\n",
       "        [0.2342, 0.9638, 0.6446, 0.8826, 0.4221, 0.4741, 0.7989, 0.4236],\n",
       "        [3.4698, 7.1701, 5.8306, 5.5481, 4.6109, 5.3777, 4.4293, 6.9727],\n",
       "        [3.4698, 7.1701, 5.8306, 5.5481, 4.6109, 5.3777, 4.4293, 6.9727],\n",
       "        [2.1296, 4.5994, 3.6825, 3.6156, 2.8758, 3.3465, 2.9255, 4.2599]],\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgl_graphConv(g, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GATConv\n",
    "Graph attention layer from Graph Attention Network\n",
    "$$h_i^{(l+1)} = \\sum_{j\\in \\mathcal{N}(i)} \\alpha_{i,j} W^{(l)} h_j^{(l)}$$\n",
    "\n",
    "where $\\alpha_{ij}$ is the attention score bewteen node $i$ and\n",
    "node $j$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\\begin{aligned}\\alpha_{ij}^{l} &= \\mathrm{softmax_i} (e_{ij}^{l})\\\\e_{ij}^{l} &= \n",
    "\\mathrm{LeakyReLU}\\left(\\vec{a}^T [W h_{i} \\| W h_{j}]\\right)\\end{aligned}\\end{align}\n",
    "$$\n",
    "\n",
    "这里的 $softmax_i$ 是对节点$i$的多个边进行归一化，不考虑其他边"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn.functional import edge_softmax\n",
    "\n",
    "\n",
    "class DGL_GATConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DGL_GATConv, self).__init__()\n",
    "        # self.W=nn.Parameter(torch.rand(in_channels,out_channels))\n",
    "        # self.a=nn.Parameter(torch.rand(2*in_channels,1))\n",
    "        self.W = nn.Linear(in_channels, out_channels, bias=False)\n",
    "        self.a_fc = nn.Linear(out_channels * 2, 1, bias=False)\n",
    "        self.leakyrelu = nn.LeakyReLU()\n",
    "\n",
    "    def edge_attention(self, edges):\n",
    "        hiW = self.W(edges.dst[\"h\"])\n",
    "        hjW = self.W(edges.src[\"h\"])\n",
    "        h_cat = torch.cat([hiW, hjW], dim=1)\n",
    "        e = self.leakyrelu(self.a_fc(h_cat))\n",
    "        return {\"e\": e}\n",
    "\n",
    "    def forward(self, g: dgl.graph, h, get_attention=False):\n",
    "        with g.local_scope():\n",
    "            g.apply_edges(self.edge_attention)\n",
    "            e = g.edata[\"e\"]\n",
    "            alpha = edge_softmax(g, e)\n",
    "            g.edata[\"alpha\"] = alpha\n",
    "            hW = self.W(h)\n",
    "\n",
    "            g.ndata[\"hW\"] = hW\n",
    "            g.update_all(fn.u_mul_e(\"hW\", \"alpha\", \"m\"), fn.sum(\"m\", \"hN\"))\n",
    "            hN = g.ndata[\"hN\"]\n",
    "\n",
    "            if get_attention:\n",
    "                return hN, alpha\n",
    "            else:\n",
    "                return hN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=5, num_edges=11,\n",
       "      ndata_schemes={'h': Scheme(shape=(8,), dtype=torch.float32)}\n",
       "      edata_schemes={})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = torch.tensor([0, 1, 1, 2, 2, 4])\n",
    "dst = torch.tensor([2, 0, 2, 3, 4, 3])\n",
    "h = torch.ones((5, 8))\n",
    "\n",
    "g = dgl.graph((src, dst))\n",
    "g = dgl.add_self_loop(g)\n",
    "g.ndata[\"h\"] = h\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "myGATConv = DGL_GATConv(8, 4)\n",
    "torch.nn.init.ones_(myGATConv.W.weight)\n",
    "torch.nn.init.ones_(myGATConv.a_fc.weight)\n",
    "\n",
    "print(myGATConv.W.weight)\n",
    "print(myGATConv.a_fc.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[8., 8., 8., 8.],\n",
       "         [8., 8., 8., 8.],\n",
       "         [8., 8., 8., 8.],\n",
       "         [8., 8., 8., 8.],\n",
       "         [8., 8., 8., 8.]], grad_fn=<GSpMMBackward>),\n",
       " tensor([[0.3333],\n",
       "         [0.5000],\n",
       "         [0.3333],\n",
       "         [0.3333],\n",
       "         [0.5000],\n",
       "         [0.3333],\n",
       "         [0.5000],\n",
       "         [1.0000],\n",
       "         [0.3333],\n",
       "         [0.3333],\n",
       "         [0.5000]], grad_fn=<EdgeSoftmaxBackward>))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myGATConv(g, h, get_attention=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 1: Homogeneous graph\n",
    "from dgl.nn import GATConv\n",
    "\n",
    "g = dgl.graph(([0, 1, 2, 3, 2, 5], [1, 2, 3, 4, 0, 3]))\n",
    "g = dgl.add_self_loop(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=5, num_edges=11,\n",
       "      ndata_schemes={'h': Scheme(shape=(8,), dtype=torch.float32)}\n",
       "      edata_schemes={})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = torch.tensor([0, 1, 1, 2, 2, 4])\n",
    "dst = torch.tensor([2, 0, 2, 3, 4, 3])\n",
    "h = torch.ones((5, 8))\n",
    "\n",
    "g = dgl.graph((src, dst))\n",
    "g = dgl.add_self_loop(g)\n",
    "g.ndata[\"h\"] = h\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[1., 1., 1., 1.]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[1., 1., 1., 1.]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "gatconv = GATConv(8, 4, num_heads=1)\n",
    "\n",
    "torch.nn.init.ones_(gatconv.fc.weight)\n",
    "torch.nn.init.ones_(gatconv.attn_l)\n",
    "torch.nn.init.ones_(gatconv.attn_r)\n",
    "\n",
    "print(gatconv.fc.weight)\n",
    "print(gatconv.attn_l)\n",
    "print(gatconv.attn_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[8., 8., 8., 8.]],\n",
       " \n",
       "         [[8., 8., 8., 8.]],\n",
       " \n",
       "         [[8., 8., 8., 8.]],\n",
       " \n",
       "         [[8., 8., 8., 8.]],\n",
       " \n",
       "         [[8., 8., 8., 8.]]], grad_fn=<AddBackward0>),\n",
       " tensor([[[0.3333]],\n",
       " \n",
       "         [[0.5000]],\n",
       " \n",
       "         [[0.3333]],\n",
       " \n",
       "         [[0.3333]],\n",
       " \n",
       "         [[0.5000]],\n",
       " \n",
       "         [[0.3333]],\n",
       " \n",
       "         [[0.5000]],\n",
       " \n",
       "         [[1.0000]],\n",
       " \n",
       "         [[0.3333]],\n",
       " \n",
       "         [[0.3333]],\n",
       " \n",
       "         [[0.5000]]], grad_fn=<EdgeSoftmaxBackward>))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gatconv(g, h, get_attention=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 完全相同耶\n",
    "# (tensor([[8., 8., 8., 8.],\n",
    "#          [8., 8., 8., 8.],\n",
    "#          [8., 8., 8., 8.],\n",
    "#          [8., 8., 8., 8.],\n",
    "#          [8., 8., 8., 8.]], grad_fn=<GSpMMBackward>),\n",
    "#  tensor([[0.3333],\n",
    "#          [0.5000],\n",
    "#          [0.3333],\n",
    "#          [0.3333],\n",
    "#          [0.5000],\n",
    "#          [0.3333],\n",
    "#          [0.5000],\n",
    "#          [1.0000],\n",
    "#          [0.3333],\n",
    "#          [0.3333],\n",
    "#          [0.5000]], grad_fn=<EdgeSoftmaxBackward>))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAGEConv\n",
    "$$\n",
    "\\begin{align}\\begin{aligned}h_{\\mathcal{N}(i)}^{(l+1)} &= \\mathrm{aggregate}\n",
    "\\left(\\{h_{j}^{l}, \\forall j \\in \\mathcal{N}(i) \\}\\right)\\\\h_{i}^{(l+1)} &= \\sigma \\left(W \\cdot \\mathrm{concat}\n",
    "(h_{i}^{l}, h_{\\mathcal{N}(i)}^{l+1}) \\right)\\\\h_{i}^{(l+1)} &= \\mathrm{norm}(h_{i}^{(l+1)})\\end{aligned}\\end{align}\n",
    "$$\n",
    "If a weight tensor on each edge is provided, the aggregation becomes:\n",
    "$$\n",
    "h_{\\mathcal{N}(i)}^{(l+1)} = \\mathrm{aggregate}\n",
    "\\left(\\{e_{ji} h_{j}^{l}, \\forall j \\in \\mathcal{N}(i) \\}\\right)\n",
    "$$\n",
    "where $e_{ji}$ is the scalar weight on the edge from node $j$ to node $i$.\n",
    "    Please make sure that $e_{ji}$ is broadcastable with $h_j^{l}$.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HbdLhvBSVYEr"
   },
   "outputs": [],
   "source": [
    "class DGL_SAGEConv(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        pass\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G955HzNxVjSu"
   },
   "source": [
    "If you want to check your answer, you can run the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PKgfXLyLVwus"
   },
   "outputs": [],
   "source": [
    "edge_index = torch.tensor([[0, 1, 1, 2, 2, 4], [2, 0, 2, 3, 4, 3]])\n",
    "x = torch.ones((5, 8))\n",
    "conv = PyG_GATConv(8, 4)\n",
    "output = conv(x, edge_index)\n",
    "print(output)\n",
    "conv = PyG_SAGEConv(8, 4)\n",
    "output = conv(x, edge_index)\n",
    "print(output)\n",
    "\n",
    "src = torch.tensor([0, 1, 1, 2, 2, 4])\n",
    "dst = torch.tensor([2, 0, 2, 3, 4, 3])\n",
    "h = torch.ones((5, 8))\n",
    "g = dgl.graph((src, dst))\n",
    "conv = DGL_GATConv(8, 4)\n",
    "output = conv(g, h)\n",
    "print(output)\n",
    "conv = DGL_SAGEConv(8, 4)\n",
    "output = conv(g, h)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "GML",
   "language": "python",
   "name": "gml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
