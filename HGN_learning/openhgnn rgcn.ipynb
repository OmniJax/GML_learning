{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d9da3b6-52bd-448d-8225-b1a82b939e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import dgl.nn as dglnn\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from openhgnn.models import BaseModel, register_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a985bc-b276-41e0-9435-99f24275435a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @register_model('myRGCN')\n",
    "# class RGCN(BaseModel):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71614f7e-b6a5-4cfa-af14-15db0cc767bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGCNlayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_feat,\n",
    "        out_feat,\n",
    "        rel_names,\n",
    "        num_bases,  #  Number of bases. If is none, use number of relations. Default: None.\n",
    "        weight=True,\n",
    "        bias=True,\n",
    "        activation=None,\n",
    "        self_loop=False,\n",
    "        dropout=0.0,\n",
    "    ):\n",
    "        super(RGCNlayer, self).__init__()\n",
    "        self.in_feat = in_feat\n",
    "        self.in_feat = in_feat\n",
    "        self.out_feat = out_feat\n",
    "        self.rel_names = rel_names\n",
    "        self.num_bases = num_bases\n",
    "        self.bias = bias\n",
    "        self.activation = activation\n",
    "        self.self_loop = self_loop\n",
    "        self.batchnorm = False\n",
    "\n",
    "        self.conv = dglnn.HeteroGraphConv(\n",
    "            {\n",
    "                rel: dglnn.GraphConv(\n",
    "                    in_feat, out_feat, norm=\"right\", weight=False, bias=False\n",
    "                )\n",
    "                for rel in rel_names\n",
    "            }\n",
    "        )\n",
    "\n",
    "        self.use_weight = weight\n",
    "        self.use_basis = num_bases < len(self.rel_names) and weight  #\n",
    "        if self.use_weight:\n",
    "            if self.use_basis:\n",
    "                self.basis = dglnn.WeightBasis(\n",
    "                    (in_feat, out_feat), num_bases, len(self.rel_names)\n",
    "                )\n",
    "            else:\n",
    "                self.weight = nn.Parameter(\n",
    "                    th.Tensor(len(self.rel_names), in_feat, out_feat)\n",
    "                )\n",
    "                nn.init.xavier_uniform_(\n",
    "                    self.weight, gain=nn.init.calculate_gain(\"relu\")\n",
    "                )\n",
    "\n",
    "        # bias\n",
    "        if bias:\n",
    "            self.h_bias = nn.Parameter(th.Tensor(out_feat))\n",
    "            nn.init.zeros_(self.h_bias)\n",
    "\n",
    "        if self.self_loop:\n",
    "            self.loop_weight = nn.Parameter(th.Tensor(in_feat, out_feat))\n",
    "            nn.init.xavier_uniform_(\n",
    "                self.loop_weight, gain=nn.init.calculate_gain(\"relu\")\n",
    "            )\n",
    "\n",
    "        if self.batchnorm:\n",
    "            self.bn = nn.BatchNorm1d(out_feat)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        def forward(self, g: dgl.DGLGraph, inputs):\n",
    "            g = g.local_var()\n",
    "            if self.use_weight:\n",
    "                weight = self.basis() if self.use_basis else self.weight\n",
    "                wdict = {\n",
    "                    self.rel_names[i]: {\"weight\": w.squeeze()}\n",
    "                    for i, w in enumerate(th.split(weight, 1, dim=0))\n",
    "                }\n",
    "            else:\n",
    "                wdict = {}\n",
    "\n",
    "            if g.is_block:\n",
    "                inputs_src = inputs\n",
    "                inputs_dst = {\n",
    "                    k: v[: g.number_of_dst_nodes(k)] for k, v in inputs.items()\n",
    "                }\n",
    "            else:\n",
    "                inputs_src = inputs_dst = inputs\n",
    "\n",
    "            hs = self.conv(g, inputs_src, mod_kwargs=wdict)\n",
    "\n",
    "            def _apply(ntype, h):\n",
    "                if self.self_loop:\n",
    "                    h = h + th.matmul(inputs_dst[ntype], self.loop_weight)\n",
    "                if self.bias:\n",
    "                    h = h + self.h_bias\n",
    "                if self.activation:\n",
    "                    h = self.activation(h)\n",
    "                if self.batchnorm:\n",
    "                    h = self.bn(h)\n",
    "                return self.dropout(h)\n",
    "\n",
    "            return {ntype: _apply(ntype, h) for ntype, h in hs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b3cacb-0701-44b6-a464-29fea9ad683e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f7c7420-3e01-4c95-9eb2-ad3264d141e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1403, 0.0395, 0.5835, 0.8673],\n",
      "        [0.4261, 0.6162, 0.7110, 0.0673],\n",
      "        [0.9705, 0.0353, 0.9909, 0.3213],\n",
      "        [0.7699, 0.5226, 0.2869, 0.1250],\n",
      "        [0.7725, 0.2516, 0.8530, 0.6372]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0.1403, 0.0395, 0.5835, 0.8673],\n",
       "         [0.4261, 0.6162, 0.7110, 0.0673]]),\n",
       " tensor([[0.9705, 0.0353, 0.9909, 0.3213],\n",
       "         [0.7699, 0.5226, 0.2869, 0.1250]]),\n",
       " tensor([[0.7725, 0.2516, 0.8530, 0.6372]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = th.rand(5, 4)\n",
    "print(e)\n",
    "\n",
    "th.split(e, 2, dim=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GML",
   "language": "python",
   "name": "gml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
